# Layout Mapper

Прототип приложения на базе **OpenCV**, **EasyOCR**, **Streamlit** и других Python-библиотек, которое:
1. Выполняет сегментацию изображений макетов веб-страницы с помощью OpenCV и формирует иерархию блоков.
2. Анализирует каждый блок, собирая информацию о координатах вершин, используемых цветах и текстовом содержимом.
3. Сохраняет результат в JSON и даёт возможность отрисовать **bounding boxes** на исходном изображении, сохранив новое изображение annotated-result.png с нанесёнными контурами найденных блоков.
4. На основе результатов в JSON позволяет сгенерировать плоскую HTML коллекцию найденных блоков в их оригинальном размере с информацией о содержащихся цветах и текстовом содержимом.

---

## 1. Установка окружения

### 1.1. Клонирование/копирование репозитория

Скопируйте файлы проекта к себе в любую удобную папку (например, `layout-mapper/`).

```bash
git clone https://github.com/sunychibo/layout-mapper.git
cd layout-mapper
```

### 1.2. Создание виртуального окружения (рекомендуется)

```bash
python -m venv venv
```
```bash
source venv/bin/activate  # Linux/Mac
# или
venv\Scripts\activate     # Windows
```

### 1.3. Установка зависимостей

```bash
pip install -r requirements.txt
```

---

## 2. Запуск приложения

Из корневой директории проекта (где лежит `app.py`) выполните:

```bash
streamlit run app.py
```

В браузере (обычно на http://localhost:8501) откроется интерфейс **Streamlit**.

---

## 3. Использование

1. **Загрузите** изображение веб-интерфейса (например, `assets/website_template_3.png`) в приложение через кнопку `Browse files`.  
2. В панели настроек в качестве дефолтных установлены оптимальные параметры, рекомендуемые для демонстрации работы. Вы можете поэкспериментировать с изменением настроек различных параметров, которые более подробно описаны ниже. Файл defaults_atomic-noise.json содержит пресет для примера режима повышенной детализацией распознования. Для сохранения изменённых настроек перед запуском процесса распознования необходимо нажать `Apply`.
3. Нажмите **Process Image**, чтобы:
   - Получить иерархию блоков (JSON) из OpenCV.  
   - Распознать цвета (`detect_colors`).  
   - Распознать текст (`extract_text` через EasyOCR).  
   - Сохранить результат в `output-coordinates.json`.  
4. В разделе «Сгенерированный JSON» вы увидите итоговую структуру.  
5. Далее нажмите **Render Bboxes**, чтобы посмотреть на отрисованные блоки поверх исходного изображения.
6. Сгенерируёте HTML, нажав кнопку "Generate HTML Collection".

### 3.1 Таблица параметров для настройки

Ниже таблица с часто регулируемыми параметрами при классическом пороговом и морфологическом анализе. Возможные диапазоны даны ориентировочно — на практике они зависят от разрешения и особенностей конкретного набора изображений.

| **Параметр**                | **Назначение**                                                                                                                                                       | **Возможный диапазон**           | **Текущее (наивное) значение** |
|-----------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------|--------------------------------|
| **threshold_method**        | Способ бинаризации: - fixed: классический `cv2.threshold(..., THRESH_BINARY_INV)` - otsu: `cv2.THRESH_OTSU` - triangle: `cv2.THRESH_TRIANGLE` - adaptive_mean: `cv2.ADAPTIVE_THRESH_MEAN_C` - adaptive_gaussian: `cv2.ADAPTIVE_THRESH_GAUSSIAN_C`                                                    | [ `fixed`, `otsu`, `triangle`, `adaptive_mean`, `adaptive_gaussian`]  | `fixed`                        |
| **threshold_value**         | Жёсткий порог для бинаризации (если выбран `fixed`)                                                                                                                  | 0–255                            | 127                            |
| **max_value**               | Значение, присваиваемое пикселям выше порога (чаще 255)                                                                                                             | 1–255                            | 255                            |
| **adaptive_block_size**     | Размер локального блока (квадрат 3×3, 5×5, 7×7, …) при `cv2.adaptiveThreshold`                                                                                       | 3–99 (шаг 2)                     | 11                             |
| **adaptive_C**              | Константа, вычитаемая из среднего (при адаптивной бинаризации)                                                                                                       | -10…10                           | 2                              |
| **morphology_kernel_size**  | Размер структурирующего элемента (например, для `cv2.getStructuringElement`)                                                                                        | 1–31 (обычно нечётные)           | 3                              |
| **morphology_iterations**   | Количество итераций для морфологических операций (erode, dilate, open, close)                                                                                       | 0–5                              | 1                              |
| **min_block_width**         | Минимальная ширина выявленного bounding box, чтобы считать объект «блоком»                                                                                          | 10–200 (зависит от изображения)  | 20                             |
| **min_block_height**        | Минимальная высота bounding box                                                                                                                                     | 10–200                           | 20                             |
| **retrieval_mode**          | Режим поиска контуров: - `cv2.RETR_EXTERNAL` (только внешние) - `cv2.RETR_TREE` (иерархия), - `cv2.RETR_CCOMP`, `cv2.RETR_LIST`                                 | [ `RETR_EXTERNAL`, `RETR_TREE`, ... ] | `RETR_EXTERNAL`               |
| **approx_method**           | Алгоритм аппроксимации контуров: - `cv2.CHAIN_APPROX_SIMPLE`, - `cv2.CHAIN_APPROX_NONE`, - `cv2.CHAIN_APPROX_TC89_L1`, - `cv2.CHAIN_APPROX_TC89_KCOS`        | [ `CHAIN_APPROX_SIMPLE`, ... ]   | `CHAIN_APPROX_SIMPLE`         |
| **min_area**                | Минимальная площадь контура (в пикселях), чтобы учесть его в результатах                                                                                           | 0–10000 (или шире)               | 0 (не используется)           |
| **max_area**                | Максимальная площадь, при превышении которой контур считается невалидным (если нужно отсекать очень большие области, кроме layout)                                  | мин. `min_area` – ∞              | ∞ (не используется)           |
| **approx_polygons**         | Флаг включения аппроксимации многоугольников (четырёхугольников) (помогает выделять точные углы вместо простого boundingRect)                                      | true/false                       | false                          |

---

## 4. Структура проекта

В проекте имеются следующие файлы/папки:

- **`app.py`** — основной файл Streamlit-приложения.
- **`modules/`** — папка с логикой обработки:
  - `opencv_processing.py` — сегментация, построение layout (OpenCV).
  - `color_processing.py` — анализ фона (цвет/градиент).
  - `text_recognition_processing.py` — OCR (EasyOCR).
  - `render_bboxes.py` — отрисовка bbox на изображении.
  - `html_processing.py` — генерация/экспорт HTML (если нужно).
- **`ui_panel.py`** — панель управления (ползунки, селекты и т. д.).
- **`output-coordinates.json`** — итоговый JSON (создаётся при «Process Image»).
- **`assets/website_template.png`** — пример изображения веб-макета для теста.
- **`requirements.txt`** — список зависимостей.

---

## 5. Потенциал и масштабируемость

- **Интеграция с ИИ**: Проект может быть расширен с помощью моделей YOLO для детекции определённых элементов (кнопки, иконки, формы), а также может быть дополнен локальными языковыми моделями (CodeParrot/GPT-Neo) для генерации кода (HTML/CSS) напрямую из полученного JSON.  
- **Автономная работа**: Использование локальных OCR (EasyOCR) и локальных ML-моделей (YOLO/CodeParrot) позволяет обходиться без внешних API, что важно для автономности проекта без необходимостит доступа к внешним сервисам.  
- **Модульная архитектура**: Каждая задача (цвет/градиент, текст, отрисовка, генерация кода) вынесена в отдельный модуль. Это упрощает поддержку и позволяет добавлять новые виды анализа (например, анализ шрифтов, полное распознавание CSS-стилей, сегментацию изображений).  
- **Будущее использование**: Можно подключить более продвинутые алгоритмы (адаптивная сегментация, классификаторы «типов» блоков - button, input, heading), а также расширить поддержку распознавания для многоязычных интерфейсов.